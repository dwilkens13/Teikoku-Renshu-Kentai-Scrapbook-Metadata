Member of Renshü Kentai, Scrap book : Teikoku Renshū Kantai Shōwa 11-nen tobei shiryō; Scrap book :帝國練習艦隊昭和十一年渡米資料, 1923/1936, Japan, Central America, United States

Kislak Center for Special Collections, Rare Books and Manuscripts, Manuscripts, Ms. Coll. 1225 
https://colenda.library.upenn.edu/catalog/81431-p37w67k8s
https://find.library.upenn.edu/catalog/9968827463503681?hld_id=resource_link_0

 




When designing my metadata fields, I knew that I would have to make unique categories, because a scrapbook is an unusual piece to analyze. Since there was so much variety within the book, 
I knew that my categories would have to be effective for many different types of materials. To understand the story and history of the scrapbook, I included the date of the original 
document(s) on each page if it was available. Even though the book is from 1936, each material within it was created at a different time and place. I think it is beneficial to know the 
origins of individual materials, not just the year the scrapbook was put together. I also had content type as metadata to track the variety of different items within the book. For content 
descriptions, I had a description column that allowed me to explain the images/text on each page. I also kept track of featured groups, people, and locations. While creating these 
sections, I made an effort not to imply any associations and to only write what was explicitly stated or shown. Since there were so many images with captions, I added an image caption tab 
to capture keywords and the raw, authentic words of each piece. This book had many smaller pamphlets, fliers, and brochures pasted into it, each with its own pages. So, in my miscellaneous 
tab, I noted whether there were multiple pages to the document. For these pieces, I only analyzed the first page because the inner pages are part of their own document. I wanted to examine 
what appeared directly on the scrapbook pages, as that is the piece I’m modeling. In my miscellaneous tab, I also included notes on how materials were pasted to the pages because I noticed 
some variation and wanted to provide more details about the piece’s physical condition. Additionally, I had a physical condition column, where I noted the wear of each page’s materials. 
Finally, I had a language tab where I recorded the languages on each page, because there were some variations and pages with multiple languages.


For the second assignment, I used OCR and HTR software to digitize the 25 pages I selected. Although my pages were not completely filled with text like a standard novel, they were 
complicated to translate to .txt files because of their irregular and inconsistent formatting. I used a variety of software, and I needed to use the both HTR and OCR because my document 
has a mixture of handwriting and print. I started with using the built in Apple OCR, and this was effective for my simpler documents, especially the postcards with no text in the images 
themselves, where the software only had to recognize a horizontal caption within a white border. For these captions, the software never made errors, but it would fail to recognize smaller 
text and would be missing rotated text. To solve this, I first rotated the images, because that helped the software recognize them as text. As the problem started to get more common, I 
resorted to ChatGPT, to use their built in OCR and HTR software, along with Tesseract (through ChatGPT). ChatGPT was surprisingly very reliable, and it only had problems with small, 
connected letters and numbers. There was also an instance with slanted text where it missed a few words.
Overall, I did not have to do much editing due to the small amount of text on most of my pages, but deciding how to record the text was difficult because of the variety of different 
formats I encountered. I wasn’t able to retain formatting due to the basic structure of the .txt files. Still, I made an attempt to order them in a way that roughly resembles their format 
in the original image, such as keeping text in similar places/groups. Many of my files were postcards, which had relatively similar formats, so after I found a software that could 
consistently work, (ChatGPT / Tesseract) I was able to complete about half of my files with minimal editing. There were times where the Tesseract OCR failed, producing a .txt file of 
gibberish, but when I asked ChatGPT to recognize the text without Tesseract, it worked perfectly fine. The main downside of ChatGPT is that it took a while to load, especially if I had a 
lot of files within the project. 
The hardest part of this process was documenting the pages that were in Japanese. These pages were difficult because ChatGPT was not great at recognizing the text. The files with Japanese 
characters had particularly difficult format as well. Examples of these difficulties include text fading, messy handwriting, vertical sentences, and small, slanted labels. For these, I 
used a free online software that was specifically designed for Japanese OCR, called i2ocr. This text recognition was significantly more accurate than ChatGPT, and looked to be fairly 
accurate, but since the formatting on the original .jpg files were so unique, it was hard to match the stripped .txt file to the original image. Still, I could recognize the first few 
phrases for each Japanese .txt file, so I could tell the software was working. If I were to have flawless .txt files, I would need a translator and a more reliable Japanese OCR software. 
Despite this, I am happy that I was able to have a mostly accurate result. 
